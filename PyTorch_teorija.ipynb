{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch teorija",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dejanbatanjac/pytorch-learning-101/blob/master/PyTorch_teorija.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tjDCEYTP_Wic",
        "colab_type": "code",
        "outputId": "3eab8825-38b0-4536-b7ab-8740e6df06af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# check if you have GPU\n",
        "import torch\n",
        "torch.cuda.is_available()\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "Im-stNTgJxpZ",
        "colab_type": "code",
        "outputId": "9bce8940-43f2-4f80-922f-961b03befb07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "# torch tensor\n",
        "import torch\n",
        "\n",
        "t = torch.tensor(1, dtype=torch.float32, requires_grad=True)\n",
        "print(t, t.shape)\n",
        "print(t.numel())\n",
        "\n",
        "t = torch.tensor([1], dtype=torch.float32, requires_grad=True)\n",
        "print(t, t.shape)\n",
        "print(t.numel())\n",
        "\n",
        "t = torch.tensor([[1]], dtype=torch.float32, requires_grad=True)\n",
        "print(t, t.shape)\n",
        "print(t.numel())\n",
        "\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., requires_grad=True) torch.Size([])\n",
            "1\n",
            "tensor([1.], requires_grad=True) torch.Size([1])\n",
            "1\n",
            "tensor([[1.]], requires_grad=True) torch.Size([1, 1])\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zOxXqhOqV8iC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "f2d24fe1-6735-4327-8219-4b104264018d"
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# softmax allways on single dimension\n",
        "\n",
        "m = nn.Softmax(dim=0)\n",
        "input = torch.randn(2, 2)\n",
        "print(input)\n",
        "\n",
        "# do the softmax on tensor\n",
        "output = m(input)\n",
        "print(output)\n",
        "\n",
        "# show that sum of tensor elemen on 0 axis is 1\n",
        "print(output.sum(0))\n",
        "\n",
        "# total sum is 2\n",
        "print(output.sum())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7773, -2.6343],\n",
            "        [-0.8799,  0.7595]])\n",
            "tensor([[0.8399, 0.0325],\n",
            "        [0.1601, 0.9675]])\n",
            "tensor([1., 1.])\n",
            "tensor(2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rB5F5qRJYwyD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# softmax exploration\n",
        "\n",
        "m = nn.Softmax(dim=1)\n",
        "input = torch.randn(2, 2)\n",
        "print(input)\n",
        "\n",
        "# do the softmax on tensor\n",
        "output = m(input)\n",
        "print(output)\n",
        "\n",
        "# show that sum of tensor element on horisontal(1) axis is 1\n",
        "print(output.sum(1))\n",
        "\n",
        "#total sum is 2\n",
        "print(output.sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pWoNF3z6YxwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "c284b91a-4252-41b6-b15d-d3a272b4a289"
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "# softmax on flatten 2D tensor\n",
        "\n",
        "m = nn.Softmax(dim=0)\n",
        "\n",
        "# flatten\n",
        "input = torch.randn(2, 2).view(-1,1)\n",
        "print(input.shape)\n",
        "print(input)\n",
        "\n",
        "# do the softmax on tensor\n",
        "output = m(input)\n",
        "print(output)\n",
        "\n",
        "# show that sum of tensor element on horisontal(1) axis is 1\n",
        "print(output.sum(0))\n",
        "\n",
        "#total sum is 2\n",
        "print(output.sum())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 1])\n",
            "tensor([[-0.4052],\n",
            "        [-1.0042],\n",
            "        [ 1.1181],\n",
            "        [ 0.5519]])\n",
            "tensor([[0.1144],\n",
            "        [0.0629],\n",
            "        [0.5248],\n",
            "        [0.2979]])\n",
            "tensor([1.])\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ajsmMzN_Wg21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "53c20938-555f-419f-bdce-2fa803cf8143"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(input[0][0])\n",
        "print(input[0][1])\n",
        "print(input[1][0])\n",
        "print(input[1][1])\n",
        "print(\"...\")\n",
        "print(np.exp(input[0][0]))\n",
        "print(np.exp(input[0][1]))\n",
        "print(np.exp(input[1][0]))\n",
        "print(np.exp(input[1][1]))\n",
        "print(\"...\")\n",
        "\n",
        "# should be the same value as output[0][0] from above\n",
        "print(np.exp(input[0][0]) / (np.exp(input[0][0]) + np.exp(input[1][0])) )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.6303)\n",
            "tensor(0.6726)\n",
            "tensor(1.1563)\n",
            "tensor(-0.6650)\n",
            "...\n",
            "tensor(1.8781)\n",
            "tensor(1.9594)\n",
            "tensor(3.1781)\n",
            "tensor(0.5143)\n",
            "...\n",
            "tensor(0.3714)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "h5zWjqi2WzdJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# implement softmax in numpy on array\n",
        "import numpy as np\n",
        "z = np.arange(5) #[0 1 2 3 4]\n",
        "print(z)\n",
        "softmax = lambda z:np.exp(z)/np.sum(np.exp(z)) #[0.01165623 0.03168492 0.08612854 0.23412166 0.63640865]\n",
        "print(softmax(z))\n",
        "\n",
        "# more gradual\n",
        "ze = np.exp(z)\n",
        "print(ze)\n",
        "zesum = np.sum(ze)\n",
        "print(zesum)\n",
        "smx = ze/zesum\n",
        "print(smx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "15g3q3SLW7j5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "6363653d-5d2d-47f7-955d-5b7a3c5d52cb"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.0077, -0.6758],\n",
            "        [ 0.2747, -1.0105]])\n",
            "tensor([[0.4178, 0.5822],\n",
            "        [0.7833, 0.2167]])\n",
            "tensor([1., 1.])\n",
            "tensor(2.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C0fxIJWCUTP4",
        "colab_type": "code",
        "outputId": "1ee58d05-1bb9-45ef-9a8f-a5de0247d923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "output = torch.randn(10, 3)\n",
        "print(output)\n",
        "prob = torch.softmax(output, dim=1)\n",
        "print(prob)\n",
        "\n",
        "classes = torch.LongTensor(10, 1).random_(0, 3)\n",
        "class_prob = torch.gather(prob, 1, classes)\n",
        "print(class_prob)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3757, -1.4919,  0.2931],\n",
            "        [-1.1108,  1.2481, -1.9035],\n",
            "        [ 0.6880, -0.4518, -0.8052],\n",
            "        [ 0.4007,  0.0176,  1.2215],\n",
            "        [-0.7799,  0.6499, -0.2792],\n",
            "        [-0.8603,  1.5121,  0.8580],\n",
            "        [ 0.5565,  0.4327, -0.3191],\n",
            "        [-0.1452,  1.2623,  0.7672],\n",
            "        [ 0.6152,  0.4147,  0.5463],\n",
            "        [-0.3109,  0.6211, -1.1291]])\n",
            "tensor([[0.4819, 0.0745, 0.4437],\n",
            "        [0.0831, 0.8793, 0.0376],\n",
            "        [0.6474, 0.2071, 0.1455],\n",
            "        [0.2529, 0.1724, 0.5747],\n",
            "        [0.1465, 0.6119, 0.2416],\n",
            "        [0.0578, 0.6199, 0.3223],\n",
            "        [0.4348, 0.3841, 0.1811],\n",
            "        [0.1320, 0.5393, 0.3287],\n",
            "        [0.3634, 0.2974, 0.3392],\n",
            "        [0.2512, 0.6380, 0.1108]])\n",
            "tensor([[0.4437],\n",
            "        [0.0831],\n",
            "        [0.1455],\n",
            "        [0.2529],\n",
            "        [0.1465],\n",
            "        [0.3223],\n",
            "        [0.1811],\n",
            "        [0.3287],\n",
            "        [0.2974],\n",
            "        [0.1108]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hRN8MFsxYM9y",
        "colab_type": "code",
        "outputId": "3f661aa0-734b-438c-9825-c5fb0504490e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# torch.nn.CrossEntropyLoss(weight=None,size_average=True)\n",
        "# This criterion combines \n",
        "# LogSoftMax and NLLLoss in one single class.\n",
        "# It is useful when training a classification problem with n classes. \n",
        "\n",
        "# If provided, the optional argument weights should be a 1D Tensor\n",
        "# assigning weight to each of the classes. \n",
        "# This is particularly useful when you have an unbalanced training set.\n",
        "\n",
        "# The input is expected to contain scores for each class.input \n",
        "# has to be a 2D Tensor of size batch x n.\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "target = torch.tensor([-1, 1])\n",
        "print(\"target:\", target)\n",
        "\n",
        "output = torch.randn(2, 10, requires_grad=True)\n",
        "print(\"output:\", output)\n",
        "\n",
        "loss = criterion(output, target)\n",
        "\n",
        "loss.backward()\n",
        "print(\"loss:\", loss)\n",
        "print(\"grad:\", output.grad)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target: tensor([-1,  1])\n",
            "output: tensor([[-0.2054,  0.9242,  0.7776,  1.8979,  0.5154, -0.0546,  0.6909,  0.3672,\n",
            "         -0.4411, -0.2741],\n",
            "        [-1.7505,  1.7689,  1.6807, -0.1904, -1.1201, -0.1727,  2.5608,  1.2809,\n",
            "         -0.5408, -0.1375]], requires_grad=True)\n",
            "loss: tensor(1.6780, grad_fn=<NllLossBackward>)\n",
            "grad: tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.0055, -0.8132,  0.1710,  0.0263,  0.0104,  0.0268,  0.4123,  0.1146,\n",
            "          0.0185,  0.0278]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3tPu-FclblEn",
        "colab_type": "code",
        "outputId": "77133e81-4ea6-4885-9a54-17cd4ea095bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "# segments\n",
        "\n",
        "a = torch.randn(3, 2)\n",
        "print(a.shape)\n",
        "print(a)\n",
        "\n",
        "\n",
        "res = a.unsqueeze(1) - a\n",
        "print(res.shape)\n",
        "print(res)\n",
        "\n",
        "\n",
        "res =  a.unsqueeze(0) - a\n",
        "print(res.shape)\n",
        "print(res)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2])\n",
            "tensor([[-0.0730, -1.8375],\n",
            "        [-1.5152, -0.0811],\n",
            "        [-1.1114,  0.9640]])\n",
            "torch.Size([3, 3, 2])\n",
            "tensor([[[ 0.0000,  0.0000],\n",
            "         [ 1.4422, -1.7564],\n",
            "         [ 1.0384, -2.8015]],\n",
            "\n",
            "        [[-1.4422,  1.7564],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [-0.4038, -1.0451]],\n",
            "\n",
            "        [[-1.0384,  2.8015],\n",
            "         [ 0.4038,  1.0451],\n",
            "         [ 0.0000,  0.0000]]])\n",
            "torch.Size([1, 3, 2])\n",
            "tensor([[[0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6s0gARcs5kin",
        "colab_type": "code",
        "outputId": "ee850d1e-9577-4dbe-c1c9-0aa1f491b9c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# CEL for albino\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "\n",
        "batch_size = 3\n",
        "a = torch.LongTensor(batch_size).random_(5)\n",
        "b = torch.randn(batch_size, 5)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "loss = criterion(b, a)\n",
        "print(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.8487)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iDPaoPPP9SFy",
        "colab_type": "code",
        "outputId": "4cb9bb02-20e8-4e74-baa8-dee643a76c81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "cell_type": "code",
      "source": [
        "# onces into zeros\n",
        "\n",
        "a = torch.zeros(5, 5)\n",
        "a[2:, 2:] = torch.ones(3, 3)\n",
        "print(a)\n",
        "\n",
        "a = torch.zeros(5, 5)\n",
        "a[2:, :-2] = torch.ones(3, 3)\n",
        "print(a)\n",
        "\n",
        "# "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1.]])\n",
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i6HrfMvOArqn",
        "colab_type": "code",
        "outputId": "7a3c45f8-629c-4bd1-8717-1418dd7bc662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# substract values on sequential index\n",
        "\n",
        "x = torch.tensor([1, 2, 4, 7, 0])\n",
        "x_diff = x[1:] - x[:-1]\n",
        "\n",
        "print(x[1:])\n",
        "print(x[:-1])\n",
        "print(x_diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2, 4, 7, 0])\n",
            "tensor([1, 2, 4, 7])\n",
            "tensor([ 1,  2,  3, -7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6pM9GVLmkjnw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}