{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Torch backward()",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dejanbatanjac/pytorch-learning-101/blob/master/Torch_backward().ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5LUyjEHRdXIT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3c4f1fc3-49c6-4431-8c5f-d18173bdbeb8"
      },
      "cell_type": "code",
      "source": [
        "# Testing the backward() method\n",
        "# RuntimeError: grad can be implicitly created only for scalar outputs\n",
        "\n",
        "import torch\n",
        "x = torch.eye(2, 2, requires_grad=True)\n",
        "y = x + 2\n",
        "\n",
        "try: y.backward()\t\n",
        "except Exception as e:\tprint(\"We found the exception: \", e)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We found the exception:  grad can be implicitly created only for scalar outputs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vPvCCf9EdrBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "18c43204-cb64-4ec4-fba5-8dd5db8216bb"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#dimension d\n",
        "d = 2\n",
        "x = torch.eye(d, d, requires_grad=True)\n",
        "y = 0.5*x+1\n",
        "z = 3*y\n",
        "\n",
        "print(\"tensor values:\")\n",
        "print(\"x:\",x, \"\\ny:\",y, \"\\nz:\",z)\n",
        "\n",
        "print(\"tensor shape:\")\n",
        "print(\"x:\",x.shape, \"\\ny:\",y.shape, \"\\nz:\",z.shape)\n",
        "\n",
        "print(\"gradient functions:\")\n",
        "print(\"x:\",x.grad_fn, \"\\ny:\",y.grad_fn, \"\\nz:\",z.grad_fn)\n",
        "\n",
        "z.backward(gradient=x)\n",
        "#z.backward()\n",
        "\n",
        "print(\"gradients:\")\n",
        "print(\"x:\",x.grad, \"\\ny:\",y.grad, \"\\nz:\",z.grad)\n",
        "\n",
        "print(\"x:\",x.grad.data.zero_())\n",
        "print(\"x:\",x.grad.data)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor values:\n",
            "x: tensor([[1., 0.],\n",
            "        [0., 1.]], requires_grad=True) \n",
            "y: tensor([[1.5000, 1.0000],\n",
            "        [1.0000, 1.5000]], grad_fn=<AddBackward0>) \n",
            "z: tensor([[4.5000, 3.0000],\n",
            "        [3.0000, 4.5000]], grad_fn=<MulBackward0>)\n",
            "tensor shape:\n",
            "x: torch.Size([2, 2]) \n",
            "y: torch.Size([2, 2]) \n",
            "z: torch.Size([2, 2])\n",
            "gradient functions:\n",
            "x: None \n",
            "y: <AddBackward0 object at 0x7ff62b830a90> \n",
            "z: <MulBackward0 object at 0x7ff62b830a58>\n",
            "gradients:\n",
            "x: tensor([[1.5000, 0.0000],\n",
            "        [0.0000, 1.5000]]) \n",
            "y: None \n",
            "z: None\n",
            "x: tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "x: tensor([[0., 0.],\n",
            "        [0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "va1eGMAOdvkz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In here we have a 1D tensor (scalar) and we can call `backward()` method on a tensor `z` even without any paramter. \n",
        "\n",
        "However, it is better to specify `z.backward(gradient=x)` because this will specify the point where to calculate the gradient.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KPJ1II26d3ue",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "ba7df59e-f81d-422b-d3f0-203d0eb4c6c8"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#dimension d\n",
        "d = 2\n",
        "x = torch.eye(d, d, requires_grad=True)\n",
        "y = 0.5*x+1\n",
        "z = 3*y\n",
        "\n",
        "print(\"tensor values:\")\n",
        "print(\"x:\",x, \"\\ny:\",y, \"\\nz:\",z)\n",
        "\n",
        "print(\"\\ntensor shape:\")\n",
        "print(\"x:\",x.shape, \"\\ny:\",y.shape, \"\\nz:\",z.shape)\n",
        "\n",
        "print(\"\\ngradient functions:\")\n",
        "print(\"x:\",x.grad_fn, \"\\ny:\",y.grad_fn, \"\\nz:\",z.grad_fn)\n",
        "\n",
        "\n",
        "r = torch.rand(d, d)\n",
        "print(\"\\nradnom tensor:\",r)\n",
        "z.backward(gradient=r)\n",
        "#z.backward(x)\n",
        "\n",
        "print(\"\\ngradients:\")\n",
        "print(\"x:\",x.grad, \"\\ny:\",y.grad, \"\\nz:\",z.grad)\n",
        "\n",
        "print(\"\\n1.5*random tensor check:\", 1.5*r)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor values:\n",
            "x: tensor([[1., 0.],\n",
            "        [0., 1.]], requires_grad=True) \n",
            "y: tensor([[1.5000, 1.0000],\n",
            "        [1.0000, 1.5000]], grad_fn=<AddBackward0>) \n",
            "z: tensor([[4.5000, 3.0000],\n",
            "        [3.0000, 4.5000]], grad_fn=<MulBackward0>)\n",
            "\n",
            "tensor shape:\n",
            "x: torch.Size([2, 2]) \n",
            "y: torch.Size([2, 2]) \n",
            "z: torch.Size([2, 2])\n",
            "\n",
            "gradient functions:\n",
            "x: None \n",
            "y: <AddBackward0 object at 0x7ff62b82f0b8> \n",
            "z: <MulBackward0 object at 0x7ff688d753c8>\n",
            "\n",
            "radnom tensor: tensor([[0.1018, 0.3811],\n",
            "        [0.8422, 0.0967]])\n",
            "\n",
            "gradients:\n",
            "x: tensor([[0.1526, 0.5717],\n",
            "        [1.2633, 0.1450]]) \n",
            "y: None \n",
            "z: None\n",
            "\n",
            "1.5*random tensor check: tensor([[0.1526, 0.5717],\n",
            "        [1.2633, 0.1450]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q0Y1WgFQeb6p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "4da4c7fc-cdcc-4d5e-8a67-5e3063798f6f"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.eye(1, 1, requires_grad=True)\n",
        "y = 0.5*x+1\n",
        "z = 3*y\n",
        "\n",
        "t = torch.tensor(42.).view(1,1)\n",
        "print(t.shape)\n",
        "z.backward(gradient=t)\n",
        "#??z.backward\n",
        "\n",
        "print(\"gradients:\")\n",
        "print(\"x:\",x.grad, \"\\ny:\",y.grad, \"\\nz:\",z.grad)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1])\n",
            "gradients:\n",
            "x: tensor([[63.]]) \n",
            "y: None \n",
            "z: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-MAq2mxqejyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6a64e845-894b-4f23-8ade-1d564b241280"
      },
      "cell_type": "code",
      "source": [
        "#note how creating a tensor in first case returns a tensor without a dimension\n",
        "\n",
        "t = torch.tensor(42.)\n",
        "print(t.shape)\n",
        "\n",
        "t = torch.tensor(42.).view(1,1)\n",
        "print(t.shape)\n",
        "\n",
        "t = 42*torch.eye(1)\n",
        "print(t.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([])\n",
            "torch.Size([1, 1])\n",
            "torch.Size([1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_UFgNCoAeu6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "38c8eace-6ea4-45da-8cee-49bf8f975618"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.eye(1, 1, requires_grad=True)\n",
        "y = 0.5*x+1\n",
        "z = 3*y\n",
        "\n",
        "z.backward(gradient=x)\n",
        "\n",
        "print(\"gradients:\")\n",
        "print(\"x:\",x.grad, \"\\ny:\",y.grad, \"\\nz:\",z.grad)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gradients:\n",
            "x: tensor([[1.5000]]) \n",
            "y: None \n",
            "z: None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}