{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Char RNN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dejanbatanjac/pytorch-learning-101/blob/master/Char_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "DJohlCUG807k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as utils\n",
        "import torch.utils.data\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "torch.manual_seed(0)\n",
        "if torch.cuda.is_available(): torch.cuda.manual_seed_all(0)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "np.random.seed(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SEsoH83qjeDD",
        "colab_type": "code",
        "outputId": "acac15bc-af3e-4659-f001-b6eb434e161a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "cell_type": "code",
      "source": [
        "! wget https://raw.githubusercontent.com/dejanbatanjac/pytorch-learning-101/master/rij.txt"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-14 12:08:05--  https://raw.githubusercontent.com/dejanbatanjac/pytorch-learning-101/master/rij.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 159216 (155K) [text/plain]\n",
            "Saving to: ‘rij.txt.2’\n",
            "\n",
            "\rrij.txt.2             0%[                    ]       0  --.-KB/s               \rrij.txt.2           100%[===================>] 155.48K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-03-14 12:08:06 (5.01 MB/s) - ‘rij.txt.2’ saved [159216/159216]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "f5G91ab31ow2",
        "colab_type": "code",
        "outputId": "dc5740c0-cf92-4dec-bfd0-eb76684f89bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "cell_type": "code",
      "source": [
        "! head rij.txt"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACT I\r\n",
            "PROLOGUE\r\n",
            "\r\n",
            "    Two households, both alike in dignity,\r\n",
            "    In fair Verona, where we lay our scene,\r\n",
            "    From ancient grudge break to new mutiny,\r\n",
            "    Where civil blood makes civil hands unclean.\r\n",
            "    From forth the fatal loins of these two foes\r\n",
            "    A pair of star-cross'd lovers take their life;\r\n",
            "    Whose misadventured piteous overthrows\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZPDcNFgyyxfX",
        "colab_type": "code",
        "outputId": "bfb8e0ab-d2d6-4bd0-eac7-fa6464b179bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "text = open('rij.txt', 'r').read() # should be simple plain text file\n",
        "chars = sorted(list(set(text)))\n",
        "chars.insert(0, \"\\0\") #cannot imagine world w/o this character\n",
        "chars.insert(1, \"\\t\") #cannot imagine world w/o this character\n",
        "print(len(chars))\n",
        "print(chars)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n",
            "['\\x00', '\\t', '\\n', ' ', '!', '&', \"'\", ',', '-', '.', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'Y', 'Z', '[', ']', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X8tu_1IKzEhP",
        "colab_type": "code",
        "outputId": "39dd7bbb-8baa-47ee-c31d-e0e653e93af0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "cell_type": "code",
      "source": [
        "data_size,vocab_size = len(text),len(chars)\n",
        "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
        "\n",
        "char_indices = { ch:i for i,ch in enumerate(chars) }\n",
        "indices_char = { i:ch for i,ch in enumerate(chars) }\n",
        "\n",
        "print(char_indices)\n",
        "print(indices_char)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data has 153168 characters, 66 unique.\n",
            "{'\\x00': 0, '\\t': 1, '\\n': 2, ' ': 3, '!': 4, '&': 5, \"'\": 6, ',': 7, '-': 8, '.': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'Y': 36, 'Z': 37, '[': 38, ']': 39, 'a': 40, 'b': 41, 'c': 42, 'd': 43, 'e': 44, 'f': 45, 'g': 46, 'h': 47, 'i': 48, 'j': 49, 'k': 50, 'l': 51, 'm': 52, 'n': 53, 'o': 54, 'p': 55, 'q': 56, 'r': 57, 's': 58, 't': 59, 'u': 60, 'v': 61, 'w': 62, 'x': 63, 'y': 64, 'z': 65}\n",
            "{0: '\\x00', 1: '\\t', 2: '\\n', 3: ' ', 4: '!', 5: '&', 6: \"'\", 7: ',', 8: '-', 9: '.', 10: ':', 11: ';', 12: '?', 13: 'A', 14: 'B', 15: 'C', 16: 'D', 17: 'E', 18: 'F', 19: 'G', 20: 'H', 21: 'I', 22: 'J', 23: 'K', 24: 'L', 25: 'M', 26: 'N', 27: 'O', 28: 'P', 29: 'Q', 30: 'R', 31: 'S', 32: 'T', 33: 'U', 34: 'V', 35: 'W', 36: 'Y', 37: 'Z', 38: '[', 39: ']', 40: 'a', 41: 'b', 42: 'c', 43: 'd', 44: 'e', 45: 'f', 46: 'g', 47: 'h', 48: 'i', 49: 'j', 50: 'k', 51: 'l', 52: 'm', 53: 'n', 54: 'o', 55: 'p', 56: 'q', 57: 'r', 58: 's', 59: 't', 60: 'u', 61: 'v', 62: 'w', 63: 'x', 64: 'y', 65: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7Hi7Y-lm0NiU",
        "colab_type": "code",
        "outputId": "7de149cd-44b6-4290-95fd-c485da597d3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "# little data preview\n",
        "idx = [char_indices[c] for c in text]    \n",
        "print(idx[:100])\n",
        "\n",
        "''.join(indices_char[i] for i in idx[:100])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[13, 15, 32, 3, 21, 2, 28, 30, 27, 24, 27, 19, 33, 17, 2, 2, 3, 3, 3, 3, 32, 62, 54, 3, 47, 54, 60, 58, 44, 47, 54, 51, 43, 58, 7, 3, 41, 54, 59, 47, 3, 40, 51, 48, 50, 44, 3, 48, 53, 3, 43, 48, 46, 53, 48, 59, 64, 7, 2, 3, 3, 3, 3, 21, 53, 3, 45, 40, 48, 57, 3, 34, 44, 57, 54, 53, 40, 7, 3, 62, 47, 44, 57, 44, 3, 62, 44, 3, 51, 40, 64, 3, 54, 60, 57, 3, 58, 42, 44, 53]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ACT I\\nPROLOGUE\\n\\n    Two households, both alike in dignity,\\n    In fair Verona, where we lay our scen'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "_X4OspfE600m",
        "colab_type": "code",
        "outputId": "a81e5226-5053-45fd-a47b-a1ad21954fed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "cell_type": "code",
      "source": [
        "cs = 8\n",
        "c_in_dat = [[] for _ in range(cs)]\n",
        "for i in range(cs):#0..7    \n",
        "    c_in_dat[i] = np.stack([idx[j] for j in range(i, len(idx)-cs-1, cs)])\n",
        "    \n",
        "\n",
        "# the prediction\n",
        "c_out_dat = [idx[j] for j in range(cs, len(idx)-cs-1, cs)]\n",
        "\n",
        "# transform list to torch tensors, and don't take the last few characters\n",
        "y  = np.stack(c_out_dat)\n",
        "\n",
        "print(\"input\")    \n",
        "for i in range(cs): print(c_in_dat[i],\"len:\" ,len(c_in_dat[i]))\n",
        "print(\"prediction:\")\n",
        "print(y, \"len:\", len(y))\n",
        "\n",
        "# we need to have the same length for all \n",
        "for i in range(cs): c_in_dat[i]= c_in_dat[i][:len(y)]\n",
        "print(\"input again after cut off\")    \n",
        "for i in range(cs): print(c_in_dat[i], \"len:\" , len(c_in_dat[i]))\n",
        "    \n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input\n",
            "[13 27  3 ... 51  3 44] len: 19145\n",
            "[15 24  3 ... 48 47 54] len: 19145\n",
            "[32 27  3 ... 44 44  9] len: 19145\n",
            "[ 3 19  3 ... 59 57  2] len: 19145\n",
            "[21 33 32 ...  3  3  2] len: 19145\n",
            "[ 2 17 62 ... 40 30  3] len: 19145\n",
            "[28  2 54 ... 53 54  3] len: 19145\n",
            "[30  2  3 ... 60 43 52] len: 19144\n",
            "prediction:\n",
            "[27  3 47 ... 51  3 44] len: 19144\n",
            "input again after cut off\n",
            "[13 27  3 ... 48 51  3] len: 19144\n",
            "[15 24  3 ... 58 48 47] len: 19144\n",
            "[32 27  3 ...  3 44 44] len: 19144\n",
            "[ 3 19  3 ... 54 59 57] len: 19144\n",
            "[21 33 32 ... 45  3  3] len: 19144\n",
            "[ 2 17 62 ...  3 40 30] len: 19144\n",
            "[28  2 54 ... 22 53 54] len: 19144\n",
            "[30  2  3 ... 60 43 52] len: 19144\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IDNuRGLMs6Gy",
        "colab_type": "code",
        "outputId": "0d58dd2d-0cf1-444e-c581-7c7dd5433976",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "cell_type": "code",
      "source": [
        "# these are the data again\n",
        "l = list()\n",
        "for i in range(cs):\n",
        "    l.append(c_in_dat[i])\n",
        "    \n",
        "\n",
        "x = np.stack(l, axis=1)\n",
        "print(len(x))\n",
        "print(x.shape)\n",
        "print(x)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "19144\n",
            "(19144, 8)\n",
            "[[13 15 32 ...  2 28 30]\n",
            " [27 24 27 ... 17  2  2]\n",
            " [ 3  3  3 ... 62 54  3]\n",
            " ...\n",
            " [48 58  3 ...  3 22 60]\n",
            " [51 48 44 ... 40 53 43]\n",
            " [ 3 47 44 ... 30 54 52]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "czhN1thjTXVH",
        "colab_type": "code",
        "outputId": "c4251ab7-1edb-41be-b7eb-5f9bfb9d34d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "# converting to tensor\n",
        "X = torch.from_numpy(x).cuda()\n",
        "Y = torch.from_numpy(y).cuda()\n",
        "\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n",
        "# batch size\n",
        "bs = 512\n",
        "\n",
        "#now we create Dataset and DataLoader\n",
        "ds = utils.TensorDataset(X, Y) \n",
        "dl = utils.DataLoader(ds, batch_size=bs, shuffle=False)\n",
        "\n",
        "\n",
        "mb, yt = next(iter(dl))\n",
        "print(\"mini-batch shape\", mb.shape)\n",
        "print(\"prediction shape\", yt.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([19144, 8])\n",
            "torch.Size([19144])\n",
            "mini-batch shape torch.Size([512, 8])\n",
            "prediction shape torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y0IMzujBYjw6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hidden activation states\n",
        "# this is something we define \n",
        "# also called hidden features\n",
        "n_hidden = 256\n",
        "\n",
        "# latent factors, the size of the input embedding\n",
        "n_fac = 33 \n",
        "\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, n_fac):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.e = nn.Embedding(vocab_size, n_fac)\n",
        "        self.rnn = nn.RNN(n_fac, n_hidden)        \n",
        "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
        "\n",
        "        \n",
        "        \n",
        "    def forward(self, *cs): \n",
        "               \n",
        "        bs = cs[0].size(0)\n",
        "        h = torch.zeros(1, bs, n_hidden).to(\"cuda\")\n",
        "        inp = self.e(torch.stack(cs))\n",
        "        outp, h = self.rnn(inp, h)\n",
        "        \n",
        "        # just return the last state (-1)\n",
        "        return torch.log_softmax(self.l_out(outp[-1]),1) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eGGkajYUTlIN",
        "colab_type": "code",
        "outputId": "ac04ecf8-b3d5-4690-b6a3-6c4846175dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "# create the model as m\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "m = CharRNN(vocab_size, n_fac).cuda()\n",
        "\n",
        "t = [o.numel() for o in m.parameters() ]\n",
        "print(t, sum(t))\n",
        "# print(list(m.parameters()))\n",
        "print(m)\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2772, 10752, 65536, 256, 256, 16896, 66] 96534\n",
            "CharRNN(\n",
            "  (e): Embedding(66, 42)\n",
            "  (rnn): RNN(42, 256)\n",
            "  (l_out): Linear(in_features=256, out_features=66, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rYmGT_FaFqDR",
        "colab_type": "code",
        "outputId": "af1d5814-4783-4f25-f041-7ff0844d16b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        }
      },
      "cell_type": "code",
      "source": [
        "# train phase\n",
        "m.train()\n",
        "\n",
        "# set Adam optimizer\n",
        "opt = optim.Adam(m.parameters(), lr = 0.001)\n",
        "\n",
        "# set the loss function\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "# would be nice to fine tune this number\n",
        "num_epochs = 40\n",
        "# once = False\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    \n",
        "    for mb,yt in dl: \n",
        "                \n",
        "        if(mb.size(0)!=bs):\n",
        "            # next epoch\n",
        "            continue\n",
        "        \n",
        "        tup = torch.unbind(mb, dim=1) \n",
        "        y_hat = m(*tup)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = loss_fn(y_hat, yt)\n",
        "\n",
        "        # go backward()\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # update params\n",
        "        opt.step()\n",
        "    \n",
        "    print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
        "        \n",
        "        \n",
        "        \n",
        "        "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/40], Loss: 2.8263\n",
            "Epoch [2/40], Loss: 2.4734\n",
            "Epoch [3/40], Loss: 2.3161\n",
            "Epoch [4/40], Loss: 2.2191\n",
            "Epoch [5/40], Loss: 2.1500\n",
            "Epoch [6/40], Loss: 2.0782\n",
            "Epoch [7/40], Loss: 2.0194\n",
            "Epoch [8/40], Loss: 1.9661\n",
            "Epoch [9/40], Loss: 1.9167\n",
            "Epoch [10/40], Loss: 1.8710\n",
            "Epoch [11/40], Loss: 1.8285\n",
            "Epoch [12/40], Loss: 1.7890\n",
            "Epoch [13/40], Loss: 1.7541\n",
            "Epoch [14/40], Loss: 1.7299\n",
            "Epoch [15/40], Loss: 1.6853\n",
            "Epoch [16/40], Loss: 1.6514\n",
            "Epoch [17/40], Loss: 1.6203\n",
            "Epoch [18/40], Loss: 1.5895\n",
            "Epoch [19/40], Loss: 1.5592\n",
            "Epoch [20/40], Loss: 1.5290\n",
            "Epoch [21/40], Loss: 1.4982\n",
            "Epoch [22/40], Loss: 1.4662\n",
            "Epoch [23/40], Loss: 1.4328\n",
            "Epoch [24/40], Loss: 1.3989\n",
            "Epoch [25/40], Loss: 1.3665\n",
            "Epoch [26/40], Loss: 1.3377\n",
            "Epoch [27/40], Loss: 1.3128\n",
            "Epoch [28/40], Loss: 1.2891\n",
            "Epoch [29/40], Loss: 1.2663\n",
            "Epoch [30/40], Loss: 1.2569\n",
            "Epoch [31/40], Loss: 1.2575\n",
            "Epoch [32/40], Loss: 1.2457\n",
            "Epoch [33/40], Loss: 1.2290\n",
            "Epoch [34/40], Loss: 1.1476\n",
            "Epoch [35/40], Loss: 1.0907\n",
            "Epoch [36/40], Loss: 1.0500\n",
            "Epoch [37/40], Loss: 1.0144\n",
            "Epoch [38/40], Loss: 0.9814\n",
            "Epoch [39/40], Loss: 0.9512\n",
            "Epoch [40/40], Loss: 0.9268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TsHkcsBnwPww",
        "colab_type": "code",
        "outputId": "9607bb2c-e1b9-434e-ca7d-dc1911a965d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "m.eval()\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# how many characters we predict\n",
        "bptt = 8\n",
        "\n",
        "# predict next bptt-th character\n",
        "def get_next(inp): \n",
        "    inp = inp[-bptt:] \n",
        "    idxs = np.array([char_indices[c] for c in inp ])\n",
        "        \n",
        "    t = torch.from_numpy(idxs).cuda() #tensor([30, 27, 24, 27, 19, 33, 17,  3], device='cuda:0')\n",
        "    unb = torch.unbind(t, dim=-1)\n",
        "\n",
        "    # set e dimension to 1 (was 0)\n",
        "    for e in unb: \n",
        "        if(e.dim()==0): e.unsqueeze_(0)\n",
        "    p = m(*unb)\n",
        "  \n",
        "    \n",
        "    # grab the index of the max element\n",
        "    max,ind = p.max(1)\n",
        "    ind = ind.item() #detach().cpu().numpy()  \n",
        "    return chars[ind]\n",
        "    \n",
        "\n",
        "\n",
        "inp = \"PROLOGUE\"\n",
        "get_next(inp)\n",
        "\n",
        "\n",
        "\n",
        "while(len(inp)<1000):\n",
        "    nc = get_next(inp)\n",
        "    inp = inp+nc\n",
        "    \n",
        "print(inp)\n",
        "\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PROLOGUE\n",
            "\n",
            "    That with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow should breads,\n",
            "    By heart foome, what not me where with thee be that vill thee slow sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JAMsQYtJN1dx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}