{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch General",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tjDCEYTP_Wic",
        "colab_type": "code",
        "outputId": "45da438b-aebb-4c39-d009-6d4824f1e9ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# check if you have GPU\n",
        "import torch\n",
        "torch.cuda.is_available()\n",
        "print(torch.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QYELs5g1Rcu9",
        "colab_type": "code",
        "outputId": "d78c7fea-ca34-4aeb-c746-d9799719beb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "t = torch.tensor(1, dtype=torch.float32, requires_grad=True)\n",
        "print(t, t.shape)\n",
        "\n",
        "t = torch.tensor([1], dtype=torch.float32, requires_grad=True)\n",
        "print(t, t.shape)\n",
        "\n",
        "t = torch.tensor([[1]], dtype=torch.float32, requires_grad=True)\n",
        "print(t, t.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1., requires_grad=True) torch.Size([])\n",
            "tensor([1.], requires_grad=True) torch.Size([1])\n",
            "tensor([[1.]], requires_grad=True) torch.Size([1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0-vdXd-sKONu",
        "colab_type": "code",
        "outputId": "038b0e97-192d-43a2-bcfe-f2d983d9d7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "# unsqueeze\n",
        "import torch\n",
        "x = torch.tensor([1, 2, 3, 4])\n",
        "print(x,x.shape)\n",
        "print(torch.unsqueeze(x, 0),torch.unsqueeze(x, 0).shape)\n",
        "print(torch.unsqueeze(x, 1),torch.unsqueeze(x, 1).shape)\n",
        "\n",
        "print(\"...\")\n",
        "print(x.view(-1,1), x.view(-1,1).shape)\n",
        "print(x.view(1,-1), x.view(1,-1).shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3, 4]) torch.Size([4])\n",
            "tensor([[1, 2, 3, 4]]) torch.Size([1, 4])\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]]) torch.Size([4, 1])\n",
            "...\n",
            "tensor([[1],\n",
            "        [2],\n",
            "        [3],\n",
            "        [4]]) torch.Size([4, 1])\n",
            "tensor([[1, 2, 3, 4]]) torch.Size([1, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "auXAXYbGE3fU",
        "colab_type": "code",
        "outputId": "00ff7ac4-f770-424c-d9ac-bc7bcbce4909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.tensor([1, 2, 3, 4]).to(\"cuda\")\n",
        "print(x.tolist()) #returns the list\n",
        "print(x.tolist()[0]) #returns the first element from the list\n",
        "print(x.data) #returns the tensor\n",
        "print(x.data[0]) # returns the first element tensor\n",
        "print(x.data[0]) # returns the first element tensor\n",
        "print(x.data[0].item()) # returns the first element"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4]\n",
            "1\n",
            "tensor([1, 2, 3, 4], device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n",
            "tensor(1, device='cuda:0')\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iMYwJsrXDpC6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import numpy as np\n",
        "\n",
        "x1 = np.array([13,3,28,24,33,2,3,62,47,58])\n",
        "x2 = np.array([15,21,30,27,17,3,3,54,54,44])\n",
        "x3 = np.array([32,2,27,19,2,3,32,3,60,47])\n",
        "\n",
        "#stack multiple tensors using np.stack\n",
        "\n",
        "md = DataLoader( np.stack([x1,x2,x3], axis=1), batch_size=512)\n",
        "#??np.stack\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kFVQ0WKMV9zt",
        "colab_type": "code",
        "outputId": "27c64986-2c40-4ddb-98c0-3761075b5cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "a = [i for i in range(50)]\n",
        "b = [i for i in range(50)]\n",
        "c = [i for i in range(50)]\n",
        "\n",
        "#h\n",
        "A = torch.Tensor(a)\n",
        "B = torch.FloatTensor(b)\n",
        "C = torch.FloatTensor(c)\n",
        "h=[A,B,C]\n",
        "\n",
        "print(len(h))\n",
        "print(h[0].size(), h[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3\n",
            "torch.Size([50]) tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
            "        14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
            "        28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n",
            "        42., 43., 44., 45., 46., 47., 48., 49.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mzmjR888wCME",
        "colab_type": "code",
        "outputId": "8ff88437-5a26-4e08-d0dd-0b98af45b731",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        }
      },
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.utils.data as utils\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# from np.array to tensor\n",
        "np_x = [np.array([[1,2],[1,3]]),np.array([[5,6],[7,8]])] # a list of numpy arrays\n",
        "np_y = [np.array([2]), np.array([3])] # another list of numpy arrays (targets)\n",
        "\n",
        "tx = torch.stack([torch.Tensor(i) for i in np_x]) # transform to torch tensors\n",
        "ty = torch.stack([torch.Tensor(i) for i in np_y])\n",
        "\n",
        "print(\"tensor x:\", tx)\n",
        "print(\"tensor y:\", ty)\n",
        "print(\"tensor x shape:\", tx.shape)\n",
        "print(\"tensor y shape:\", ty.shape)\n",
        "\n",
        "# Dataset is an abstract class. We cannot use it directly.\n",
        "# We use TensorDataset class.\n",
        "# The tensor(s) in there should have the same size of the first dimension.\n",
        "\n",
        "# create datset\n",
        "ds = utils.TensorDataset(tx, ty) \n",
        "\n",
        "# try setting shuffle=False|True\n",
        "dl = utils.DataLoader(ds, batch_size=1, shuffle=False) \n",
        "\n",
        "\n",
        "# DataLoader knows the batch size. Try setting {1|2} instead\n",
        "dl = utils.DataLoader(ds, batch_size=2, shuffle=True) \n",
        "\n",
        "\n",
        "it =iter(dl)\n",
        "works = True\n",
        "while works:\n",
        "    try:\n",
        "        *r, l = next(it)\n",
        "        print(\"--\")\n",
        "        print(r)\n",
        "        print(l)\n",
        "        \n",
        "\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        works = False\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor x: tensor([[[1., 2.],\n",
            "         [1., 3.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n",
            "tensor y: tensor([[2.],\n",
            "        [3.]])\n",
            "tensor x shape: torch.Size([2, 2, 2])\n",
            "tensor y shape: torch.Size([2, 1])\n",
            "--\n",
            "[tensor([[[5., 6.],\n",
            "         [7., 8.]],\n",
            "\n",
            "        [[1., 2.],\n",
            "         [1., 3.]]])]\n",
            "tensor([[3.],\n",
            "        [2.]])\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TQPajDyqVm4q",
        "colab_type": "code",
        "outputId": "eb263750-9552-45d7-f546-7ec95c4ea552",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "cell_type": "code",
      "source": [
        "import torch \n",
        "import torch.utils.data as utils\n",
        "\n",
        "# from list to tensor\n",
        "l_x = [ [[1,2],[1,3]], [[5,6],[7,8]] ] # a list of numpy arrays\n",
        "l_y = [ [2],[2]] # another list of numpy arrays (targets)\n",
        "\n",
        "# transform to torch tensors\n",
        "tx = torch.stack([torch.Tensor(i) for i in l_x]) \n",
        "ty = torch.stack([torch.Tensor(i) for i in l_y])\n",
        "\n",
        "print(tx)\n",
        "print(ty)\n",
        "print(tx.shape, ty.shape)\n",
        "\n",
        "# Dataset is an abstract class. We cannot use it directly.\n",
        "# We use TensorDataset class.\n",
        "# The tensor(s) in there should have the same size of the first dimension.\n",
        "\n",
        "# create datset\n",
        "ds = utils.TensorDataset(tx, ty) \n",
        "# create dataloader\n",
        "dl = utils.DataLoader(ds, batch_size=1, shuffle=True) \n",
        "\n",
        "# print what we have inside\n",
        "print(\"==\")\n",
        "for i in ds: print(i)\n",
        "print(type(i))\n",
        "print(\"==\")\n",
        "for i in dl: print(i)\n",
        "print(type(i))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[1., 2.],\n",
            "         [1., 3.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n",
            "tensor([[2.],\n",
            "        [2.]])\n",
            "torch.Size([2, 2, 2]) torch.Size([2, 1])\n",
            "==\n",
            "(tensor([[1., 2.],\n",
            "        [1., 3.]]), tensor([2.]))\n",
            "(tensor([[5., 6.],\n",
            "        [7., 8.]]), tensor([2.]))\n",
            "<class 'tuple'>\n",
            "==\n",
            "[tensor([[[5., 6.],\n",
            "         [7., 8.]]]), tensor([[2.]])]\n",
            "[tensor([[[1., 2.],\n",
            "         [1., 3.]]]), tensor([[2.]])]\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tteSJcj1LmR6",
        "colab_type": "code",
        "outputId": "37d2ee4a-94c5-4e20-b4ed-12f5e96fdfe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "tensor = torch.randn((1, 2), requires_grad=True)\n",
        "\n",
        "print(torch.tanh(tensor))\n",
        "print(nn.Tanh()(tensor))\n",
        "\n",
        "#nn.functional.tanh is deprecated\n",
        "#print(torch.nn.functional.tanh(tensor))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8146, 0.7732]], grad_fn=<TanhBackward>)\n",
            "tensor([[0.8146, 0.7732]], grad_fn=<TanhBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UlDWW98_csWg",
        "colab_type": "code",
        "outputId": "dc332dc5-bbc7-4668-b8c1-64a87cb26eac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "x = torch.zeros(2,1,2,1,2)\n",
        "print(x.size())\n",
        "\n",
        "# all dimensions of size 1 will be removed\n",
        "y = torch.squeeze(x)\n",
        "print(y.size())\n",
        "\n",
        "# we may specify particular dimension to squeeze\n",
        "# in here 0 will not do anything\n",
        "y = torch.squeeze(x, 0)\n",
        "print(y.size())\n",
        "\n",
        "# we may specify particular dimension to squeeze\n",
        "# in here 1 will squeeze single dimension\n",
        "y = torch.squeeze(x, 1)\n",
        "print(y.size())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 2, 1, 2])\n",
            "torch.Size([2, 2, 2])\n",
            "torch.Size([2, 1, 2, 1, 2])\n",
            "torch.Size([2, 2, 1, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GlWTvkgxcDis",
        "colab_type": "code",
        "outputId": "98631f38-8fde-4441-bae4-9e77c4fd440c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "# * \n",
        "*bb, bbb = [1,2,3,4,5,6,7]\n",
        "print(bb)\n",
        "print(bbb)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HiVV1bYme71J",
        "colab_type": "code",
        "outputId": "60722d0c-aa6c-4896-ded0-d0c8de9778bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "x = torch.zeros(2,1)\n",
        "print(x.size())\n",
        "print(x)\n",
        "\n",
        "# all dimensions of size 1 will be removed\n",
        "y = torch.squeeze(x)\n",
        "print(y.size())\n",
        "print(y)\n",
        "\n",
        "# to be same as x\n",
        "z = torch.unsqueeze(y, dim=1)\n",
        "print(z.size())\n",
        "print(z)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1])\n",
            "tensor([[0.],\n",
            "        [0.]])\n",
            "torch.Size([2])\n",
            "tensor([0., 0.])\n",
            "torch.Size([2, 1])\n",
            "tensor([[0.],\n",
            "        [0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bK9iFxjRS-eM",
        "colab_type": "code",
        "outputId": "fbd63c02-70ab-4fb6-9ec6-b1a0084d605b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# from np.array -> tensor\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "#a = np.array([1, 2, 3])\n",
        "a = np.random.rand(3,2)\n",
        "t = torch.from_numpy(a)\n",
        "print(t)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.0307, 0.9624],\n",
            "        [0.8289, 0.9290],\n",
            "        [0.4454, 0.1031]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oXMyzWPhhDpl",
        "colab_type": "code",
        "outputId": "cd0859cb-446b-4406-a197-306fd598058d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "print(torch.__version__) #1.0.1.post2\n",
        "#stacking example\n",
        "a = torch.randn(2,3,4)\n",
        "b = torch.randn(2,3)\n",
        "print(a.size())\n",
        "print(b.size())\n",
        "b = torch.unsqueeze(b, dim=2)  # 2, 3, 1\n",
        "print(b.size())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2\n",
            "torch.Size([2, 3, 4])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 3, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kGkY7fEyzPyI",
        "colab_type": "code",
        "outputId": "2625f860-a637-428e-e2b2-3cc94a7cd760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__) # 1.0.1.post2\n",
        "#stacking example\n",
        "a = torch.randn(2,3,4)\n",
        "b = torch.randn(2,3)\n",
        "print(a.size()) # 2, 3, 4\n",
        "print(b.size()) # 2, 3\n",
        "b = torch.unsqueeze(b, dim=2)  \n",
        "print(b.size()) # 2, 3, 1\n",
        "\n",
        "r = torch.cat((a,b), dim=2)\n",
        "# r = torch.stack([a, b], dim=2 )\n",
        "print(r.shape)\n",
        "print(r)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.1.post2\n",
            "torch.Size([2, 3, 4])\n",
            "torch.Size([2, 3])\n",
            "torch.Size([2, 3, 1])\n",
            "torch.Size([2, 3, 5])\n",
            "tensor([[[ 0.0139,  0.6015, -1.6427,  0.9218, -0.4895],\n",
            "         [-1.4400,  1.8444,  0.5984,  1.7035, -0.7307],\n",
            "         [-0.4477, -0.0331, -1.7182, -1.9063,  0.6845]],\n",
            "\n",
            "        [[ 0.2214,  0.3788, -1.1672,  0.4438, -0.6435],\n",
            "         [ 0.9548,  1.5609,  1.2947,  0.5860,  0.7537],\n",
            "         [ 1.5375, -0.5452, -0.9654,  1.0114,  0.2838]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vbJ1ugXXh0k5",
        "colab_type": "code",
        "outputId": "ae3be17d-ad6d-4521-949e-a9c79520e4c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "#transpose 2D Tensor (dimensions 0 <=> 1)\n",
        "x = torch.randn(2, 3)\n",
        "print(x)\n",
        "y = torch.t(x)\n",
        "print(y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.7538,  0.3490,  0.4196],\n",
            "        [ 0.8518,  0.2454, -0.4683]])\n",
            "tensor([[ 0.7538,  0.8518],\n",
            "        [ 0.3490,  0.2454],\n",
            "        [ 0.4196, -0.4683]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Ov5jJnumeyt",
        "colab_type": "code",
        "outputId": "5e8caf3a-a258-4a9c-949b-05ec40537a6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#get tensor based on indices\n",
        "\n",
        "arr=torch.tensor([[1,2],[4,5],[7,8]])\n",
        "indices_arr=torch.tensor([0,1,0])\n",
        "\n",
        "ret=arr[[0,1,2],indices_arr]\n",
        "print(ret, type(ret))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 5, 7]) <class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WJWLA4fVUyPG",
        "colab_type": "code",
        "outputId": "722c1db8-ec4e-461d-c5ce-dacb63c29463",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = torch.Tensor([1,2,3,4,5])\n",
        "print(a.shape)\n",
        "print(a)\n",
        "\n",
        "a.unsqueeze_(dim=1)\n",
        "print(a.shape)\n",
        "print(a)\n",
        "\n",
        "# a.unsqueeze_(dim=0)\n",
        "# print(a.shape)\n",
        "# print(a)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5])\n",
            "tensor([1., 2., 3., 4., 5.])\n",
            "torch.Size([5, 1])\n",
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sCnB6IyV1U66",
        "colab_type": "code",
        "outputId": "fab3934a-6eec-43b7-f933-e685e4272cf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "# smart indexing example\n",
        "import torch\n",
        "\n",
        "x = torch.arange(0, 10, dtype=torch.float)\n",
        "print(x)\n",
        "\n",
        "# getting indexes idx where x>=5\n",
        "idx = x>=5\n",
        "print(idx, type(idx))\n",
        "\n",
        "# log on values where x was >=5\n",
        "x[idx] = torch.log(x[idx])\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "tensor([0, 0, 0, 0, 0, 1, 1, 1, 1, 1], dtype=torch.uint8) <class 'torch.Tensor'>\n",
            "tensor([0.0000, 1.0000, 2.0000, 3.0000, 4.0000, 1.6094, 1.7918, 1.9459, 2.0794,\n",
            "        2.1972])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bTc4DSXdUW7p",
        "colab_type": "code",
        "outputId": "cac9d8a4-6de2-4f0f-e8c1-01504a8a51e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# random integers 3x3 taken from 0..100 range\n",
        "x = torch.randint(0, 256, (3, 3))\n",
        "print(x)\n",
        "\n",
        "# we take k=1 largest (topk function) per row\n",
        "k = 2\n",
        "\n",
        "# kvals = values of the largest\n",
        "# kidx = indices of the largest\n",
        "vals, idxs = x.topk(k=k, dim=1)\n",
        "\n",
        "print(\"kvals:\", vals, \"\\nkidx:\", idxs)\n",
        "\n",
        "# set all elements to zero\n",
        "x.zero_()\n",
        "print(x)\n",
        "\n",
        "print(\"dim of x:\", x.size(0))  # dimension=3\n",
        "\n",
        "# set 1 only these elements where we had largest value based on idxs\n",
        "x[torch.arange(x.size(0))[:, None], idxs] = 1\n",
        "print(x)\n",
        "\n",
        "# set 1 only these elements where we had largest value based on idxs\n",
        "x[torch.arange(x.size(0)).unsqueeze_(1), idxs]=1\n",
        "print(x)\n",
        "\n",
        "\n",
        "# print(torch.arange(x.size(0))[:, None])\n",
        "# print(torch.arange(3).unsqueeze_(1))\n",
        "# print(torch.arange(x.size(0)).unsqueeze_(1).shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 63, 136, 168],\n",
            "        [135, 132,  43],\n",
            "        [183, 254,  21]])\n",
            "kvals: tensor([[168, 136],\n",
            "        [135, 132],\n",
            "        [254, 183]]) \n",
            "kidx: tensor([[2, 1],\n",
            "        [0, 1],\n",
            "        [1, 0]])\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "dim of x: 3\n",
            "tensor([[0, 1, 1],\n",
            "        [1, 1, 0],\n",
            "        [1, 1, 0]])\n",
            "tensor([[0, 1, 1],\n",
            "        [1, 1, 0],\n",
            "        [1, 1, 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OExVyyvn6Gmm",
        "colab_type": "code",
        "outputId": "cfbe5283-4641-4b43-9586-bb6d393a4a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# given the matrix of indices (index)\n",
        "# set 1 after the index on a zero tensor a\n",
        "\n",
        "# size 3x5\n",
        "a = torch.zeros(3,5)\n",
        "\n",
        "# tensor of first index where 1 starts\n",
        "index = torch.LongTensor([2, 1, 3])\n",
        "\n",
        "print(index)\n",
        "print(index.unsqueeze(1))\n",
        "\n",
        "b = torch.arange(a.size(1)).unsqueeze(0) >= index.unsqueeze(1)\n",
        "print(b)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2, 1, 3])\n",
            "tensor([[2],\n",
            "        [1],\n",
            "        [3]])\n",
            "tensor([[0, 0, 1, 1, 1],\n",
            "        [0, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 1, 1]], dtype=torch.uint8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fiM-Bc-F_gRH",
        "colab_type": "code",
        "outputId": "919ecba6-5a42-47e3-e755-f3b9ada3b2d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "cell_type": "code",
      "source": [
        "x = torch.arange(1, 17).float().view(1, 1, 4, 4)\n",
        "x\n",
        "\n",
        "\n",
        "kh, kw = 2, 2  # kernel_size\n",
        "dh, dw = 2, 2  # stride\n",
        "\n",
        "\n",
        "# get all image windows of size (kh, kw) and stride (dh, dw)\n",
        "input_windows = x.unfold(2, kh, dh).unfold(3, kw, dw)\n",
        "output = input_windows.contiguous().view(x.size())\n",
        "\n",
        "output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.,  2.,  5.,  6.],\n",
              "          [ 3.,  4.,  7.,  8.],\n",
              "          [ 9., 10., 13., 14.],\n",
              "          [11., 12., 15., 16.]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "Uk6qTkMbNmyY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "05LofUB3WXes",
        "colab_type": "code",
        "outputId": "e6f603c0-7a6d-4acf-eb6a-1f75602586a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "import torch #leaves act as accumulators\n",
        "\n",
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)\n",
        "\n",
        "y = w * x + b    # y = 2 * x + 3\n",
        "\n",
        "y.backward(retain_graph=True)\n",
        "y.backward()\n",
        "x.backward()\n",
        "x.backward()\n",
        "b.backward()\n",
        "b.backward()\n",
        "b.backward()\n",
        "w.backward()\n",
        "print(\"x grad sum:\", x.grad)\n",
        "print(\"w grad sum:\", w.grad)\n",
        "print(\"b grad sum:\", b.grad)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x grad sum: tensor(6.)\n",
            "w grad sum: tensor(3.)\n",
            "b grad sum: tensor(5.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hRN8MFsxYM9y",
        "colab_type": "code",
        "outputId": "e86611f7-98be-4617-86f9-adaec8599bf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# CrossEntropyLoss combines ogSoftMax and NLLLoss in one single class.\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
        "\n",
        "target = torch.tensor([-1, 1])\n",
        "print(\"target:\", target)\n",
        "\n",
        "output = torch.randn(2, 10, requires_grad=True)\n",
        "print(\"output:\", output)\n",
        "\n",
        "loss = criterion(output, target)\n",
        "\n",
        "loss.backward()\n",
        "print(\"loss:\", loss)\n",
        "print(\"grad:\", output.grad)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "target: tensor([-1,  1])\n",
            "output: tensor([[-0.3006, -0.4965, -0.7837,  0.8808, -2.1041,  0.3351, -0.4520,  1.4443,\n",
            "          1.2511, -1.0921],\n",
            "        [-1.4941, -0.2283, -0.9850, -1.0050, -0.8326,  1.2723,  0.7116, -0.7330,\n",
            "          0.1446, -0.3722]], requires_grad=True)\n",
            "loss: tensor(2.5434, grad_fn=<NllLossBackward>)\n",
            "grad: tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
            "          0.0000,  0.0000],\n",
            "        [ 0.0222, -0.9214,  0.0369,  0.0361,  0.0429,  0.3525,  0.2012,  0.0474,\n",
            "          0.1141,  0.0681]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3tPu-FclblEn",
        "colab_type": "code",
        "outputId": "896c90c4-3d0e-4821-c0fe-dd9388042417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "cell_type": "code",
      "source": [
        "# unsquezze in different dimensions\n",
        "\n",
        "a = torch.randn(3, 2)\n",
        "print(a)\n",
        "\n",
        "res = a.unsqueeze(1) - a\n",
        "print(res)\n",
        "\n",
        "res =  a.unsqueeze(0) - a\n",
        "print(res)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.3614,  0.2802],\n",
            "        [-1.5333, -2.2783],\n",
            "        [-0.5929, -1.5980]])\n",
            "tensor([[[ 0.0000,  0.0000],\n",
            "         [ 1.8946,  2.5586],\n",
            "         [ 0.9543,  1.8782]],\n",
            "\n",
            "        [[-1.8946, -2.5586],\n",
            "         [ 0.0000,  0.0000],\n",
            "         [-0.9404, -0.6804]],\n",
            "\n",
            "        [[-0.9543, -1.8782],\n",
            "         [ 0.9404,  0.6804],\n",
            "         [ 0.0000,  0.0000]]])\n",
            "tensor([[[0., 0.],\n",
            "         [0., 0.],\n",
            "         [0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uVJODz_heS8R",
        "colab_type": "code",
        "outputId": "53caf242-a0f9-4116-8bf3-4d4842ef6fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# extract single item from torch.tensor\n",
        "import torch\n",
        "a = torch.tensor(10)\n",
        "a = a.item()\n",
        "print(a)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iDPaoPPP9SFy",
        "colab_type": "code",
        "outputId": "763fb479-e66a-407a-8d0a-c0b241a78fcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        }
      },
      "cell_type": "code",
      "source": [
        "a = torch.zeros(5, 5)\n",
        "a[2:, 2:] = torch.ones(3, 3)\n",
        "print(a)\n",
        "\n",
        "a = torch.zeros(5, 5)\n",
        "a[2:, :-2] = torch.ones(3, 3)\n",
        "print(a)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1.],\n",
            "        [0., 0., 1., 1., 1.]])\n",
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i6HrfMvOArqn",
        "colab_type": "code",
        "outputId": "60777da7-33b6-42fb-dd51-7f9ec00bd713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "# torch operations like numpy\n",
        "\n",
        "x = torch.tensor([1, 2, 4, 7, 0])\n",
        "x_diff = x[1:] - x[:-1]\n",
        "\n",
        "print(x[1:])\n",
        "print(x[:-1])\n",
        "print(x_diff)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2, 4, 7, 0])\n",
            "tensor([1, 2, 4, 7])\n",
            "tensor([ 1,  2,  3, -7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5hRB_n4E-oZp",
        "colab_type": "code",
        "outputId": "f6bee4cd-e3df-41ef-a090-905cbd52fef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.tensor(20)\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(x.size())\n",
        "print(x.dim())\n",
        "x.unsqueeze_(0)\n",
        "print(x)\n",
        "print(x.shape)\n",
        "print(x.size())\n",
        "print(x.dim())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(20)\n",
            "torch.Size([])\n",
            "torch.Size([])\n",
            "0\n",
            "tensor([20])\n",
            "torch.Size([1])\n",
            "torch.Size([1])\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n6r_sUrr8_y8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "outputId": "4dabbde0-706e-4783-9bf4-1fa58e4053b4"
      },
      "cell_type": "code",
      "source": [
        "# leaf or not a leaf \n",
        "import torch\n",
        "\n",
        "\n",
        "# Tensors that have requires_grad False will be leaf tensors by convention.\n",
        "# For tensors that have requires_grad which is True, they will be leaf Tensors \n",
        "# if they were created by the user. \n",
        "# This means that they are not the result of an operation and so grad_fn is None.\n",
        "\n",
        "a = torch.rand(10, requires_grad=False) # a is a leaf variable by convention\n",
        "print(a.is_leaf, a.grad_fn, a.grad)\n",
        "a = torch.rand(10, requires_grad=True) # a is a leaf variable created by the user\n",
        "print(a.is_leaf, a.grad_fn, a.grad)\n",
        "a = torch.rand(10, requires_grad=True).double() # a is NOT a leaf variable as it was created by the operation that cast a float tensor into a double tensor\n",
        "print(a.is_leaf, a.grad_fn, a.grad)\n",
        "a = torch.rand(10).requires_grad_().double() # equivalent to the formulation just above: not a leaf variable\n",
        "print(a.is_leaf, a.grad_fn, a.grad)\n",
        "a = torch.rand(10).double() # a does not require gradients and has not operation creating it (tracked by the autograd engine).\n",
        "print(a.is_leaf, a.grad_fn, a.grad)\n",
        "a = torch.rand(10).double().requires_grad_() # a requires gradients and has no operations creating it: it's a leaf variable and can be given to an optimizer.\n",
        "print(a.is_leaf, a.grad_fn, a.grad)\n",
        "a = torch.rand(10, requires_grad=True, device=\"cuda\") # a requires grad, has not operation creating it: it's a leaf variable as well and can be given to an optimizer\n",
        "print(a.is_leaf, a.grad_fn, a.grad)\n",
        "\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True None None\n",
            "True None None\n",
            "False <CopyBackwards object at 0x7fd501b663c8> None\n",
            "False <CopyBackwards object at 0x7fd501b66390> None\n",
            "True None None\n",
            "True None None\n",
            "True None None\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}